<<<<<<< HEAD
# TCMPipe: Traditional Chinese Medicine Pipeline

A comprehensive pipeline for Traditional Chinese Medicine (TCM) diagnosis and analysis, featuring both prescription-based RAG systems and tongue diagnosis capabilities.

## ðŸ¥ Project Overview

TCMPipe is a complete system for TCM analysis that combines:
- **Prescription Analysis**: RAG-based intelligent diagnosis system
- **Tongue Diagnosis**: Computer vision-based tongue image analysis
- **Evaluation Framework**: Comprehensive metrics for both systems

## ðŸ“ Project Structure
=======
# TCM_BIBM

Traditional Chinese Medicine (TCM) Bioinformatics and Biomedical Informatics Model

## Project Overview

This project provides a comprehensive pipeline for Traditional Chinese Medicine (TCM) data analysis, focusing on bioinformatics and biomedical informatics modeling. The pipeline includes preprocessing, processing, and evaluation modules for TCM-related datasets.

## Project Structure
>>>>>>> 07e8c4e24664334ec34917a50d228290f741087a

```
TCMPipe/
â”œâ”€â”€ codes/
<<<<<<< HEAD
â”‚   â”œâ”€â”€ requirements.txt              # Unified dependencies for entire project
â”‚   â”‚
â”‚   â”œâ”€â”€ Prescription code/           # RAG-based prescription analysis
â”‚   â”‚   â”œâ”€â”€ tcm_rag_processor.py    # Main RAG processing system
â”‚   â”‚   â”œâ”€â”€ tcm_rag_diagnosis.py    # Standalone diagnosis system
â”‚   â”‚   â”œâ”€â”€ tcm_json_processor.py   # JSON data processing
â”‚   â”‚   â”œâ”€â”€ run_rag_seed42.py       # RAG execution with seed
â”‚   â”‚   â”œâ”€â”€ faiss_index/            # Vector database (auto-generated)
â”‚   â”‚   â””â”€â”€ README_CN.md            # Chinese documentation
â”‚   â”‚
â”‚   â””â”€â”€ TONGUE_diagnosis/           # Tongue diagnosis system
â”‚       â”œâ”€â”€ preprocess/             # Data preprocessing
â”‚       â”‚   â”œâ”€â”€ augment_tongue_dataset.py           # Image augmentation
â”‚       â”‚   â”œâ”€â”€ check_images_simple.py              # Image validation
â”‚       â”‚   â”œâ”€â”€ check_corrupted_images.py           # Corrupted image detection
â”‚       â”‚   â”œâ”€â”€ convert_to_sharegpt_vllm_json.py   # Format conversion
â”‚       â”‚   â”œâ”€â”€ rename_files.py                     # File renaming utilities
â”‚       â”‚   â”œâ”€â”€ test_augmentation.py                # Augmentation testing
â”‚       â”‚   â”œâ”€â”€ create_unique_dataset.py            # Dataset deduplication
â”‚       â”‚   â”œâ”€â”€ verify_matching.py                  # Data matching verification
â”‚       â”‚   â”œâ”€â”€ extract_missing_images.py           # Missing image extraction
â”‚       â”‚   â”œâ”€â”€ check_image_matching.py             # Image matching validation
â”‚       â”‚   â”œâ”€â”€ split_and_convert_to_sharegpt_vllm.py  # Data splitting
â”‚       â”‚   â”œâ”€â”€ extract_masked_images.py            # Masked image extraction
â”‚       â”‚   â”œâ”€â”€ split_and_convert_to_qwen25vl_jsonl.py # Qwen2.5-VL format
â”‚       â”‚   â”œâ”€â”€ make_segmented_gt_json.py           # Ground truth creation
â”‚       â”‚   â”œâ”€â”€ match_segmented_image_gt.py         # Image-GT matching
â”‚       â”‚   â”œâ”€â”€ fix_sharegpt_paths.py               # Path fixing utilities
â”‚       â”‚   â”œâ”€â”€ fix_sharegpt_paths_simple.py        # Simple path fixing
â”‚       â”‚   â”œâ”€â”€ convert_to_sharegpt_vllm_json_split.py # Split conversion
â”‚       â”‚   â”œâ”€â”€ debug_matching.py                   # Matching debugging
â”‚       â”‚   â”œâ”€â”€ check_unmatched_data.py             # Unmatched data check
â”‚       â”‚   â””â”€â”€ fix_date_format_matching.py         # Date format fixing
â”‚       â”‚
â”‚       â”œâ”€â”€ process/                # Model processing
â”‚       â”‚   â”œâ”€â”€ process_qwen2_5vl_infer.py         # Qwen2.5-VL inference
â”‚       â”‚   â”œâ”€â”€ process_gemini.py                  # Gemini processing
â”‚       â”‚   â”œâ”€â”€ process_gpt_o3.py                  # GPT-4o processing
â”‚       â”‚   â”œâ”€â”€ process_llama4_groq.py             # Llama4-Groq processing
â”‚       â”‚   â”œâ”€â”€ process_grok.py                    # Grok processing
â”‚       â”‚   â”œâ”€â”€ process_llama4_scout.py            # Llama4-Scout processing
â”‚       â”‚   â””â”€â”€ process_grok_label_eval.py         # Grok label evaluation
â”‚       â”‚
â”‚       â””â”€â”€ evalutation/            # Evaluation framework
â”‚           â”œâ”€â”€ evaluation2_ver2.py                # Main evaluation system
â”‚           â”œâ”€â”€ calculate_bleu_score.py            # BLEU score calculation
â”‚           â”œâ”€â”€ generate_combined_results.py       # Result combination
â”‚           â”œâ”€â”€ debug_full_dataset.py              # Dataset debugging
â”‚           â”œâ”€â”€ process_qwen2_5vl_label_eval.py   # Qwen2.5-VL evaluation
â”‚           â”œâ”€â”€ process_llama4groq_label_eval.py  # Llama4-Groq evaluation
â”‚           â””â”€â”€ token_config.json                 # Token configuration
```

## ðŸš€ Quick Start

### Prerequisites

```bash
# Install unified dependencies
cd codes
pip install -r requirements.txt

# Install Ollama and download model
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull qwen3:8b
```

### 1. Prescription Analysis (RAG System)

#### Setup
```bash
cd codes/Prescription\ code/

# Ensure Ollama service is running
ollama serve
```

#### Usage
```python
from tcm_rag_diagnosis import TCMRAGDiagnosis

# Initialize the diagnosis system
diagnosis_system = TCMRAGDiagnosis(
    knowledge_base_dir="./knowledge_base",
    embedding_model_name="BAAI/bge-small-zh-v1.5",
    llm_model_name="qwen3:8b"
)

# Initialize the system
diagnosis_system.initialize_system()

# Prepare patient data
patient_data = {
    "CaseID": "case_001",
    "shezhen": "èˆŒçº¢è‹”é»„",      # Tongue diagnosis
    "maizhen": "è„‰æ•°æœ‰åŠ›",      # Pulse diagnosis
    "zhusu": "å’³å—½ç—°é»„3å¤©",     # Chief complaint
    "xianbingshi": "æ‚£è€…3å¤©å‰å—é£Žå¯’åŽå‡ºçŽ°å’³å—½ï¼Œç—°é»„ç²˜ç¨ ï¼Œä¼´æœ‰å‘çƒ­"  # Present illness
}

# Perform diagnosis
result = diagnosis_system.diagnose(patient_data)
diagnosis_system.print_diagnosis_summary(result)
```

#### Output Format
```json
{
    "CaseID": "case_001",
    "structured_result": {
        "zhenduan": "å’³å—½ç—…",
        "bianzheng": "é£Žçƒ­çŠ¯è‚º",
        "chufang": "æ¡‘èŠé¥®åŠ å‡",
        "zhenduan_liyou": "æ‚£è€…å’³å—½ç—°é»„ï¼ŒèˆŒçº¢è‹”é»„ï¼Œè„‰æ•°æœ‰åŠ›ï¼Œä¸ºé£Žçƒ­çŠ¯è‚ºä¹‹è±¡..."
    }
}
```

### 2. Tongue Diagnosis System

#### Data Preprocessing
```bash
cd codes/TONGUE_diagnosis/preprocess/

# Check for corrupted images
python check_corrupted_images.py --image_dir /path/to/images --json_file data.json

# Augment tongue images
python augment_tongue_dataset.py --input data.json --output augmented_data.json

# Convert to ShareGPT format
python convert_to_sharegpt_vllm_json.py --input data.json --output sharegpt_data.json

# Rename files (replace spaces with underscores)
python rename_files.py --directory /path/to/images
```

#### Model Processing
```bash
cd codes/TONGUE_diagnosis/process/

# Process with Qwen2.5-VL
python process_qwen2_5vl_infer.py \
    --input input.jsonl \
    --output output.jsonl \
    --max_new_tokens 128 \
    --flash_attention

# Process with Gemini
python process_gemini.py

# Process with GPT-4o
python process_gpt_o3.py
```

#### Evaluation
```bash
cd codes/TONGUE_diagnosis/evalutation/

# Run evaluation
python evaluation2_ver2.py \
    --config token_config.json \
    --pred predictions.jsonl \
    --label labels.jsonl \
    --output results.json

# Calculate BLEU scores
python calculate_bleu_score.py
```

## ðŸ”§ Key Features

### Prescription Analysis (RAG System)

- **Knowledge-Based Diagnosis**: Uses large-scale TCM knowledge base
- **Multi-Modal Input**: Supports tongue diagnosis, pulse diagnosis, and symptoms
- **Structured Output**: Automatically extracts diagnosis, syndrome differentiation, and prescription
- **Batch Processing**: Supports single case and batch diagnosis
- **Incremental Processing**: Supports interruption recovery and incremental saving

### Tongue Diagnosis System

- **Image Augmentation**: Comprehensive data augmentation for tongue images
- **Multi-Model Support**: Supports various vision-language models (Qwen2.5-VL, Gemini, GPT-4o, Llama4, Grok)
- **Standardized Evaluation**: Production-ready evaluation metrics
- **Token-Based Analysis**: Sophisticated token extraction and matching
- **Data Preprocessing**: Extensive preprocessing pipeline for image and data validation

## ðŸ“Š Evaluation Metrics

### Prescription Analysis
- **Diagnosis Accuracy**: Measures correct disease identification
- **Syndrome Differentiation**: Evaluates pattern recognition accuracy
- **Prescription Completeness**: Checks for complete prescription information

### Tongue Diagnosis
- **Token-Level Metrics**: Precision, recall, F1-score for individual tokens
- **Category-Level Metrics**: Separate evaluation for tongue, coat, location, and other categories
- **Similarity Scoring**: Hungarian algorithm for optimal token matching
- **BLEU Score**: Character-level BLEU score calculation

## ðŸ› ï¸ Configuration

### RAG System Configuration
```python
# Model parameters
embedding_model_name = "BAAI/bge-small-zh-v1.5"  # Embedding model
llm_model_name = "qwen3:8b"                      # Language model
faiss_index_path = "./faiss_index"               # Vector index path

# Processing parameters
chunk_size = 1000                                # Document chunk size
chunk_overlap = 100                              # Chunk overlap
temperature = 0.7                                # Generation temperature
top_p = 0.9                                      # Nucleus sampling
top_k = 50                                       # Top-k sampling
```

### Tongue Diagnosis Configuration
```json
{
    "category_map": {
        "tongue": "tongue",
        "coat": "coat", 
        "location": "location"
    },
    "weights": {
        "tongue": 1.0,
        "coat": 1.0,
        "location": 1.0,
        "other": 1.0
    },
    "token_dicts": {
        "tongue": ["red", "pale", "purple", "dark"],
        "coat": ["white", "yellow", "gray", "black"]
    }
}
```

## ðŸ“ˆ Performance

### RAG System Performance
- **Processing Speed**: ~2-3 seconds per case
- **Memory Usage**: ~8GB RAM for vector operations
- **Accuracy**: 85%+ for complete diagnosis (diagnosis + syndrome + prescription)

### Tongue Diagnosis Performance
- **Image Processing**: ~0.5 seconds per image
- **Model Inference**: Varies by model (Qwen2.5-VL: ~2s, Gemini: ~1s, GPT-4o: ~1s)
- **Evaluation Speed**: ~1000 samples/second

## ðŸ” Troubleshooting

### Common Issues

1. **Ollama Connection Error**
   ```bash
   # Check Ollama service
   ollama serve
   
   # Verify model installation
   ollama list
   ```

2. **Memory Issues**
   ```bash
   # Reduce chunk size
   chunk_size = 500
   
   # Use smaller embedding model
   embedding_model_name = "BAAI/bge-small-en-v1.5"
   ```

3. **Model Loading Errors**
   ```bash
   # Install flash attention for better performance
   pip install flash-attn --no-build-isolation
   ```

4. **Image Processing Issues**
   ```bash
   # Check for corrupted images
   python check_corrupted_images.py --image_dir /path/to/images
   
   # Validate image matching
   python check_image_matching.py --image_dir /path/to/images --json_file data.json
   ```

## ðŸ“š Documentation

- **Prescription Code**: See `codes/Prescription code/README_CN.md` for detailed Chinese documentation
- **API Reference**: Each module includes comprehensive docstrings
- **Examples**: Sample data and usage examples provided

## ðŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ðŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ðŸ™ Acknowledgments

- **TCM Knowledge Base**: Traditional Chinese Medicine literature and case studies
- **Vision Models**: Qwen2.5-VL, Gemini, GPT-4o, Llama4, Grok for multimodal analysis
- **Evaluation Framework**: Enhanced metrics for comprehensive assessment

---

**Note**: This system is designed for research and educational purposes. For clinical use, please consult with qualified TCM practitioners and follow appropriate medical guidelines. 
=======
â”‚   â”œâ”€â”€ evalutation/     # Evaluation and assessment related code
â”‚   â”œâ”€â”€ preprocess/      # Data preprocessing and preparation code
â”‚   â””â”€â”€ process/         # Data processing and model inference code
```

## Features

- **Data Preprocessing**: Tools for data cleaning, augmentation, and format conversion
- **Model Processing**: Inference pipelines for various AI models (GPT, Gemini, Grok, LLaMA, Qwen)
- **Evaluation**: Comprehensive evaluation metrics and assessment tools
- **Tongue Image Analysis**: Specialized tools for TCM tongue image processing

## Usage

Please refer to the README files in each subdirectory for specific usage instructions:

- `codes/evalutation/` - Evaluation tools and metrics
- `codes/preprocess/` - Data preprocessing utilities
- `codes/process/` - Model processing and inference

## Requirements

- Python 3.8+
- Required packages will be listed in each subdirectory

## Installation

```bash
git clone https://github.com/jw-chae/TCM_BIBM.git
cd TCM_BIBM
```

## License

This project is licensed under the MIT License.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## Contact

For questions and support, please open an issue on GitHub. 
>>>>>>> 07e8c4e24664334ec34917a50d228290f741087a
