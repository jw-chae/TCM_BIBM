#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TCM RAG Diagnosis System - Standalone Version

Features:
- Knowledge-based TCM intelligent diagnosis
- Support for tongue diagnosis, pulse diagnosis and other multi-dimensional information
- Structured output of diagnosis, syndrome differentiation, prescription and reasoning

Usage:
1. Ensure required dependencies are installed: pip install -r requirements.txt
2. Ensure Ollama service is running and qwen3:8b model is installed
3. Run: python tcm_rag_diagnosis.py

"""

import os
import re
import json
import time
from typing import Dict, Any, Optional
from operator import itemgetter

# LangChainç›¸å…³å¯¼å…¥
try:
    from langchain_community.document_loaders import DirectoryLoader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_community.embeddings import HuggingFaceBgeEmbeddings
    from langchain_community.vectorstores import FAISS
    from langchain_community.llms import Ollama
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·å®‰è£…ä¾èµ–: pip install -r requirements.txt")
    exit(1)


class TCMRAGDiagnosis:
    """TCM RAG Diagnosis System"""
    
    def __init__(self, 
                 knowledge_base_dir="./knowledge_base",
                 embedding_model_name="BAAI/bge-small-zh-v1.5",
                 llm_model_name="qwen3:8b",
                 faiss_index_path="./faiss_index"):
        
        self.knowledge_base_dir = knowledge_base_dir
        self.embedding_model_name = embedding_model_name
        self.llm_model_name = llm_model_name
        self.faiss_index_path = faiss_index_path
        
        # Initialize components
        self.vectorstore = None
        self.llm = None
        self.rag_chain = None
        
        # Prompt template
        self.prompt_template = """
ä½ æ˜¯ä¸€åä¸­åŒ»ä¸“å®¶ï¼Œæ ¹æ®èµ„æ–™åº“ä¸­æä¾›çš„èµ„æ–™ä»¥åŠæ‚£è€…ä¿¡æ¯ï¼ˆæ‚£è€…ç°çŠ¶ã€èˆŒè¯Šã€è„‰è¯Šï¼‰ï¼Œç»™å‡ºè¯Šæ–­ã€è¾©è¯ã€å¤„æ–¹å’Œè¯Šæ–­ç†ç”±ã€‚

ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼Œä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–å†…å®¹ï¼š

è¯Šæ–­: [ç—…å]
è¾©è¯: [è¾©è¯ç»“æœ]
å¤„æ–¹: [è¯ç‰©1] [å‰‚é‡]   [è¯ç‰©2] [å‰‚é‡]   [è¯ç‰©3] [å‰‚é‡]   ã€ç”¨æ³•ç”¨é‡ã€‘[ç”¨æ³•è¯´æ˜]
è¯Šæ–­ç†ç”±: [è¯¦ç»†çš„è¯Šæ–­åˆ†æå’Œç†ç”±ï¼ŒåŒ…æ‹¬ç—‡çŠ¶åˆ†æã€èˆŒè„‰åˆ†æã€ç—…æœºé˜è¿°]

è¦æ±‚ï¼š
1. å¿…é¡»è¾“å‡ºä¸Šè¿°å››è¡Œï¼Œæ¯è¡Œä»¥"è¯Šæ–­:"ã€"è¾©è¯:"ã€"å¤„æ–¹:"ã€"è¯Šæ–­ç†ç”±:"å¼€å¤´
2. è¯Šæ–­ç®€æ´æ˜ç¡®ï¼Œ2-8ä¸ªå­—
3. è¾©è¯å‡†ç¡®ï¼Œ4-8ä¸ªå­—
4. å¤„æ–¹ä¸­æ¯ä¸ªè¯ç‰©ç”¨"   "ï¼ˆä¸‰ä¸ªç©ºæ ¼ï¼‰åˆ†éš”ï¼Œé¿å…é‡å¤è¯ç‰©
5. å¿…é¡»åŒ…å«ã€ç”¨æ³•ç”¨é‡ã€‘éƒ¨åˆ†
6. è¯Šæ–­ç†ç”±è¦è¯¦ç»†ï¼ŒåŒ…å«ç—‡çŠ¶åˆ†æã€èˆŒè„‰åˆ†æã€ç—…æœºé˜è¿°
7. ä¸è¦è¾“å‡ºæ€è€ƒè¿‡ç¨‹ã€è§£é‡Šæˆ–å…¶ä»–ä»»ä½•å†…å®¹

ç¤ºä¾‹ï¼š
è¯Šæ–­: å¤´ç—›ç—…
è¾©è¯: è‚é˜³ä¸Šäº¢
å¤„æ–¹: å¤©éº» 10g   é’©è—¤ 15g   çŸ³å†³æ˜ 20g   ç‰›è† 12g   æœä»² 15g   ç›Šæ¯è‰ 15g   æ¡‘å¯„ç”Ÿ 15g   å¤œäº¤è—¤ 15g   èŒ¯ç¥ 12g   ã€ç”¨æ³•ç”¨é‡ã€‘å…±7å‰‚ï¼Œç…æœ1æ—¥2æ¬¡1æ—¥1å‰‚ æ¯æ¬¡200ml
è¯Šæ–­ç†ç”±: æ‚£è€…å¤´ç—›å¤´æ™•ï¼ŒèˆŒçº¢è‹”é»„ï¼Œè„‰å¼¦æ•°ï¼Œä¸ºè‚é˜³ä¸Šäº¢ä¹‹è±¡ã€‚è‚é˜³åäº¢ï¼Œä¸Šæ‰°æ¸…çªåˆ™å¤´ç—›å¤´æ™•ï¼›è‚ç«å†…ç››ï¼Œç¼æ´¥æˆç—°ï¼Œæ•…èˆŒçº¢è‹”é»„ï¼›è‚æ°”éƒç»“ï¼Œæ°”æœºä¸ç•…ï¼Œæ•…è„‰å¼¦æ•°ã€‚æ²»å®œå¹³è‚æ½œé˜³ï¼Œæ»‹é˜´é™ç«ã€‚

ä¸Šä¸‹æ–‡: 
{context}

é—®é¢˜: {question}
"""

    def load_and_process_documents(self, directory_path: str):
        """åŠ è½½æŒ‡å®šç›®å½•ä¸‹çš„ .txt æ–‡æ¡£ï¼Œå¹¶è¿›è¡Œåˆ‡åˆ†"""
        print("ğŸ“š å¼€å§‹åŠ è½½å’Œå¤„ç†çŸ¥è¯†åº“æ–‡æ¡£...")
        
        if not os.path.exists(directory_path):
            print(f"âŒ çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨: {directory_path}")
            return None
            
        loader = DirectoryLoader(directory_path, glob="**/*.txt", show_progress=True)
        documents = loader.load()
        
        if not documents:
            print(f"âŒ åœ¨ç›®å½• '{directory_path}' ä¸‹æœªæ‰¾åˆ°ä»»ä½• .txt æ–‡æ¡£")
            return None

        print(f"âœ… æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
        
        # æ–‡æ¡£åˆ‡åˆ†
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\\n\\n", "\\n", "ã€‚", "ï¼›", "ï¼Œ", " ", ""]
        )
        
        split_docs = text_splitter.split_documents(documents)
        print(f"âœ… æ–‡æ¡£åˆ‡åˆ†å®Œæˆï¼Œå…± {len(split_docs)} ä¸ªæ–‡æ¡£å—")
        
        return split_docs

    def create_and_save_vectorstore(self, docs, embedding_model_name: str, index_path: str):
        """åˆ›å»ºå¹¶ä¿å­˜å‘é‡æ•°æ®åº“"""
        print("ğŸ”„ åˆ›å»ºå‘é‡æ•°æ®åº“...")
        
        try:
            embeddings = HuggingFaceBgeEmbeddings(
                model_name=embedding_model_name,
                encode_kwargs={'normalize_embeddings': True}
            )
            
            vectorstore = FAISS.from_documents(docs, embeddings)
            vectorstore.save_local(index_path)
            print(f"âœ… å‘é‡æ•°æ®åº“åˆ›å»ºå¹¶ä¿å­˜åˆ°: {index_path}")
            return vectorstore
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºå‘é‡æ•°æ®åº“æ—¶å‡ºé”™: {e}")
            return None

    def load_vectorstore(self, index_path: str, embedding_model_name: str):
        """åŠ è½½å·²å­˜åœ¨çš„å‘é‡æ•°æ®åº“"""
        print("ğŸ“– åŠ è½½å‘é‡æ•°æ®åº“...")
        
        try:
            embeddings = HuggingFaceBgeEmbeddings(
                model_name=embedding_model_name,
                encode_kwargs={'normalize_embeddings': True}
            )
            
            vectorstore = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)
            print("âœ… å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ")
            return vectorstore
            
        except Exception as e:
            print(f"âŒ åŠ è½½å‘é‡æ•°æ®åº“æ—¶å‡ºé”™: {e}")
            return None

    def initialize_system(self):
        """åˆå§‹åŒ–RAGç³»ç»Ÿ"""
        print("ğŸš€ åˆå§‹åŒ–ä¸­åŒ»RAGè¯Šæ–­ç³»ç»Ÿ...")
        
        # æ£€æŸ¥FAISSç´¢å¼•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.faiss_index_path):
            docs = self.load_and_process_documents(self.knowledge_base_dir)
            if docs:
                self.vectorstore = self.create_and_save_vectorstore(docs, self.embedding_model_name, self.faiss_index_path)
            else:
                print("âŒ æœªèƒ½å¤„ç†ä»»ä½•æ–‡æ¡£ï¼Œç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
                return False
        else:
            # åŠ è½½å·²å­˜åœ¨çš„å‘é‡æ•°æ®åº“
            self.vectorstore = self.load_vectorstore(self.faiss_index_path, self.embedding_model_name)
        
        if not self.vectorstore:
            print("âŒ å‘é‡æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥")
            return False

        # åˆå§‹åŒ–Ollama LLM
        try:
            print(f"ğŸ¤– åˆå§‹åŒ–LLMæ¨¡å‹: {self.llm_model_name}")
            self.llm = Ollama(model=self.llm_model_name)
            
            # æµ‹è¯•æ¨¡å‹è¿æ¥
            test_response = self.llm.invoke("ä½ å¥½")
            print("âœ… LLMæ¨¡å‹è¿æ¥æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ LLMæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            print("è¯·ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œå¹¶å·²å®‰è£…æŒ‡å®šæ¨¡å‹")
            return False
        
        # åˆ›å»ºæ£€ç´¢å™¨
        retriever = self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 5}
        )
        
        # åˆ›å»ºæç¤ºæ¨¡æ¿
        prompt = ChatPromptTemplate.from_template(self.prompt_template)
        
        # åˆ›å»ºRAGé“¾
        self.rag_chain = (
            {
                "context": itemgetter("question") | retriever,
                "question": itemgetter("question")
            }
            | prompt
            | self.llm
            | StrOutputParser()
        )
        
        print("âœ… RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        return True

    def format_patient_info(self, patient_data: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æ‚£è€…ä¿¡æ¯ä¸ºæŸ¥è¯¢æ–‡æœ¬"""
        query_parts = []
        
        if patient_data.get('zhusu'):
            query_parts.append(f"ä¸»è¯‰ï¼š{patient_data['zhusu']}")
        
        if patient_data.get('xianbingshi'):
            query_parts.append(f"ç°ç—…å²ï¼š{patient_data['xianbingshi']}")
        
        if patient_data.get('shezhen'):
            query_parts.append(f"èˆŒè¯Šï¼š{patient_data['shezhen']}")
        
        if patient_data.get('maizhen'):
            query_parts.append(f"è„‰è¯Šï¼š{patient_data['maizhen']}")
        
        return "\\n".join(query_parts)

    def extract_structured_info(self, response: str) -> Dict[str, str]:
        """ä»RAGå“åº”ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯"""
        result = {
            'zhenduan': '',
            'bianzheng': '',
            'chufang': '',
            'zhenduan_liyou': ''
        }
        
        try:
            lines = response.strip().split('\\n')
            
            for line in lines:
                line = line.strip()
                if line.startswith('è¯Šæ–­:'):
                    result['zhenduan'] = line.replace('è¯Šæ–­:', '').strip()
                elif line.startswith('è¾©è¯:'):
                    result['bianzheng'] = line.replace('è¾©è¯:', '').strip()
                elif line.startswith('å¤„æ–¹:'):
                    result['chufang'] = line.replace('å¤„æ–¹:', '').strip()
                elif line.startswith('è¯Šæ–­ç†ç”±:'):
                    result['zhenduan_liyou'] = line.replace('è¯Šæ–­ç†ç”±:', '').strip()
        
        except Exception as e:
            print(f"âš ï¸ ä¿¡æ¯æå–å‡ºé”™: {e}")
        
        return result

    def diagnose(self, patient_data: Dict[str, Any]) -> Dict[str, Any]:
        """è¿›è¡Œä¸­åŒ»è¯Šæ–­"""
        if not self.rag_chain:
            print("âŒ RAGç³»ç»Ÿæœªåˆå§‹åŒ–")
            return None
        
        try:
            # æ ¼å¼åŒ–æ‚£è€…ä¿¡æ¯
            query = self.format_patient_info(patient_data)
            print(f"ğŸ” æŸ¥è¯¢å†…å®¹ï¼š\\n{query}")
            
            # æ‰§è¡ŒRAGæŸ¥è¯¢
            print("ğŸ¤” æ­£åœ¨åˆ†æè¯Šæ–­...")
            start_time = time.time()
            response = self.rag_chain.invoke({"question": query})
            end_time = time.time()
            
            print(f"â±ï¸ è¯Šæ–­å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
            print(f"ğŸ¥ åŸå§‹è¯Šæ–­ç»“æœï¼š\\n{response}")
            
            # æå–ç»“æ„åŒ–ä¿¡æ¯
            structured_result = self.extract_structured_info(response)
            
            # æ„å»ºå®Œæ•´ç»“æœ
            diagnosis_result = {
                'CaseID': patient_data.get('CaseID', f'case_{int(time.time())}'),
                'patient_info': patient_data,
                'raw_response': response,
                'structured_result': structured_result,
                'diagnosis_time': time.strftime('%Y-%m-%d %H:%M:%S')
            }
            
            return diagnosis_result
            
        except Exception as e:
            print(f"âŒ è¯Šæ–­è¿‡ç¨‹å‡ºé”™: {e}")
            return None

    def batch_diagnose(self, patients_data: list) -> list:
        """æ‰¹é‡è¯Šæ–­"""
        results = []
        total = len(patients_data)
        
        print(f"ğŸ¥ å¼€å§‹æ‰¹é‡è¯Šæ–­ï¼Œå…± {total} ä¸ªæ¡ˆä¾‹")
        
        for i, patient_data in enumerate(patients_data, 1):
            print(f"\\nğŸ“‹ å¤„ç†æ¡ˆä¾‹ {i}/{total}: {patient_data.get('CaseID', 'Unknown')}")
            
            result = self.diagnose(patient_data)
            if result:
                results.append(result)
                print(f"âœ… æ¡ˆä¾‹ {i} è¯Šæ–­å®Œæˆ")
            else:
                print(f"âŒ æ¡ˆä¾‹ {i} è¯Šæ–­å¤±è´¥")
        
        print(f"\\nğŸ‰ æ‰¹é‡è¯Šæ–­å®Œæˆï¼æˆåŠŸè¯Šæ–­ {len(results)}/{total} ä¸ªæ¡ˆä¾‹")
        return results

    def save_results(self, results: list, filename: str = "diagnosis_results.json"):
        """ä¿å­˜è¯Šæ–­ç»“æœ"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ è¯Šæ–­ç»“æœå·²ä¿å­˜åˆ°: {filename}")
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

    def print_diagnosis_summary(self, result: Dict[str, Any]):
        """æ‰“å°è¯Šæ–­æ‘˜è¦"""
        if not result:
            return
        
        structured = result.get('structured_result', {})
        patient = result.get('patient_info', {})
        
        print("\\n" + "="*60)
        print(f"ğŸ“‹ æ¡ˆä¾‹ID: {result.get('CaseID', 'N/A')}")
        print(f"â° è¯Šæ–­æ—¶é—´: {result.get('diagnosis_time', 'N/A')}")
        print("-"*60)
        print(f"ğŸ‘¤ æ‚£è€…ä¿¡æ¯:")
        print(f"   ä¸»è¯‰: {patient.get('zhusu', 'N/A')}")
        print(f"   èˆŒè¯Š: {patient.get('shezhen', 'N/A')}")
        print(f"   è„‰è¯Š: {patient.get('maizhen', 'N/A')}")
        print("-"*60)
        print(f"ğŸ¥ è¯Šæ–­ç»“æœ:")
        print(f"   è¯Šæ–­: {structured.get('zhenduan', 'N/A')}")
        print(f"   è¾©è¯: {structured.get('bianzheng', 'N/A')}")
        print(f"   å¤„æ–¹: {structured.get('chufang', 'N/A')}")
        print(f"   ç†ç”±: {structured.get('zhenduan_liyou', 'N/A')}")
        print("="*60)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¥ ä¸­åŒ»RAGè¯Šæ–­ç³»ç»Ÿ v1.0")
    print("="*60)
    
    # åˆ›å»ºè¯Šæ–­ç³»ç»Ÿå®ä¾‹
    diagnosis_system = TCMRAGDiagnosis()
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    if not diagnosis_system.initialize_system():
        print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
        return
    
    # ç¤ºä¾‹æ‚£è€…æ•°æ®
    sample_patients = [
        {
            "CaseID": "demo_case_1",
            "shezhen": "èˆŒçº¢è‹”é»„",
            "maizhen": "è„‰æ•°æœ‰åŠ›",
            "zhusu": "å’³å—½ç—°é»„3å¤©",
            "xianbingshi": "æ‚£è€…3å¤©å‰å—é£å¯’åå‡ºç°å’³å—½ï¼Œç—°é»„ç²˜ç¨ ï¼Œä¼´æœ‰å‘çƒ­ï¼Œå£å¹²å–œé¥®"
        },
        {
            "CaseID": "demo_case_2", 
            "shezhen": "èˆŒæ·¡è‹”ç™½",
            "maizhen": "è„‰ç»†å¼±",
            "zhusu": "ä¹åŠ›å¤±çœ 1æœˆ",
            "xianbingshi": "æ‚£è€…è¿‘1æœˆæ¥ç²¾ç¥ç–²å€¦ï¼Œå¤œå¯ä¸å®‰ï¼Œé£Ÿæ¬²ä¸æŒ¯ï¼Œå¤§ä¾¿æºè–„"
        }
    ]
    
    print("\\nğŸ§ª ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæµ‹è¯•è¯Šæ–­...")
    
    # å•ä¸ªæ¡ˆä¾‹è¯Šæ–­æ¼”ç¤º
    print("\\nğŸ“‹ å•æ¡ˆä¾‹è¯Šæ–­æ¼”ç¤º:")
    result = diagnosis_system.diagnose(sample_patients[0])
    if result:
        diagnosis_system.print_diagnosis_summary(result)
    
    # æ‰¹é‡è¯Šæ–­æ¼”ç¤º
    print("\\nğŸ“‹ æ‰¹é‡è¯Šæ–­æ¼”ç¤º:")
    batch_results = diagnosis_system.batch_diagnose(sample_patients)
    
    # ä¿å­˜ç»“æœ
    if batch_results:
        diagnosis_system.save_results(batch_results, "demo_diagnosis_results.json")
    
    print("\\nâœ¨ æ¼”ç¤ºå®Œæˆï¼")
    print("\\nğŸ“– ä½¿ç”¨è¯´æ˜:")
    print("1. ä¿®æ”¹sample_patientsåˆ—è¡¨æ·»åŠ æ‚¨çš„æ‚£è€…æ•°æ®")
    print("2. è°ƒç”¨diagnosis_system.diagnose(patient_data)è¿›è¡Œå•ä¾‹è¯Šæ–­") 
    print("3. è°ƒç”¨diagnosis_system.batch_diagnose(patients_list)è¿›è¡Œæ‰¹é‡è¯Šæ–­")
    print("4. ä½¿ç”¨diagnosis_system.save_results()ä¿å­˜ç»“æœ")


if __name__ == "__main__":
    main()
